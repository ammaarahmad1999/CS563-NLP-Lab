{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "mount_file_id": "1OMcpa2vhukSdFv7k8eGozDLQPKoAzdIw",
      "authorship_tag": "ABX9TyM0Wl/1IC4u6BXsAcSf8eet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammaarahmad1999/CS563-NLP-Lab/blob/main/LAB2/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload Folder to colab or mount gdrive\n",
        "%cp /content/drive/MyDrive/CS563_LAB2_Dataset/* ./"
      ],
      "metadata": {
        "id": "bbYqAavmCd0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhuC7b9059Ne"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from nltk.util import ngrams\n",
        "from tabulate import tabulate\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "  text, tags = [], []\n",
        "  tag_set = set()\n",
        "  with open(filename) as f:\n",
        "    lines = f.readlines()\n",
        "    sent, tag = \"\", []\n",
        "    for line in lines:\n",
        "      item = line.split()\n",
        "      if(len(item) == 2):\n",
        "        sent += item[0]+\" \"\n",
        "        tag.append(item[1])\n",
        "        tag_set.add(item[1])\n",
        "      else:\n",
        "        text.append(sent)\n",
        "        tags.append(tag)\n",
        "        sent, tag = \"\", []\n",
        "  text = np.asarray(text, dtype = 'object')\n",
        "  tags = np.asarray(tags, dtype = 'object')\n",
        "  return text, tags, tag_set"
      ],
      "metadata": {
        "id": "oVSNCCkB7u7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transition_matrix(y):\n",
        "    \n",
        "    trigram_tags = []\n",
        "    for tag_list in y:\n",
        "        tag_list = [\"START\"] * 3 + tag_list + [\"STOP\"]\n",
        "        trigram_tags.extend(ngrams(tag_list, 3))\n",
        "    trigram_count = dict(Counter(trigram_tags))\n",
        "\n",
        "    bigram_tags = []\n",
        "    for tag_list in y:\n",
        "        tag_list = [\"START\"] * 2 + tag_list + [\"STOP\"]\n",
        "        bigram_tags.extend(ngrams(tag_list, 2))\n",
        "    bigram_count = dict(Counter(bigram_tags))\n",
        "\n",
        "    unigram_tags = []\n",
        "    for tag_list in y:\n",
        "        tag_list = [\"START\"] + tag_list + [\"STOP\"]\n",
        "        unigram_tags.extend(tag_list)\n",
        "    unigram_count = dict(Counter(unigram_tags))\n",
        "\n",
        "    tri_transition_matrix = defaultdict(lambda: 0.0000000001)\n",
        "    bi_transition_matrix = defaultdict(lambda: 0.0000000001)\n",
        "\n",
        "    for trigram in trigram_count:\n",
        "        first, second, third = trigram\n",
        "        tri_transition_matrix[trigram] = trigram_count[trigram] / bigram_count[(first, second)]\n",
        "    \n",
        "    for bigram in bigram_count:\n",
        "        first, second = bigram\n",
        "        bi_transition_matrix[bigram] = bigram_count[bigram] / unigram_count[first]\n",
        "\n",
        "    return tri_transition_matrix, bi_transition_matrix"
      ],
      "metadata": {
        "id": "2oNYw8qyNu7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_emission_matrix(x, y):\n",
        "    word_tag_count = defaultdict(lambda: 0)\n",
        "    tag_count = defaultdict(lambda: 0)\n",
        "\n",
        "    for line, tags in zip(x, y):\n",
        "        for word, tag in zip(line.split(), tags):\n",
        "            tag_count[tag] += 1\n",
        "            word_tag_count[(word, tag)] += 1\n",
        "    \n",
        "    emission_matrix = defaultdict(lambda: 0.0000000001)\n",
        "    \n",
        "    for word_tag in word_tag_count.keys():\n",
        "        word, tag = word_tag\n",
        "        emission_matrix[word_tag] = word_tag_count[word_tag] / tag_count[tag]\n",
        "    \n",
        "    word_tag_count = defaultdict(lambda: 0)\n",
        "    tag_count = defaultdict(lambda: 0)\n",
        "\n",
        "    for line, tags in zip(x, y):\n",
        "        tags = ['START'] + tags\n",
        "        for i, word in enumerate(line.split()):\n",
        "            tag_count[(tags[i], tags[i+1])] += 1\n",
        "            word_tag_count[(word, tags[i], tags[i+1])] += 1\n",
        "\n",
        "    emission_context = defaultdict(lambda: 0.0000000001)\n",
        "\n",
        "    for word_tag in word_tag_count.keys():\n",
        "        word, tag1, tag2 = word_tag\n",
        "        emission_context[word_tag] = word_tag_count[word_tag] / tag_count[(tag1, tag2)]\n",
        "\n",
        "    return emission_matrix, emission_context"
      ],
      "metadata": {
        "id": "BSWX7Vz6Ntlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collapse_to_3_tags(y_train, y_valid, y_test):\n",
        "    \n",
        "    y_train_new = [[tag[0] for tag in tag_seq] for tag_seq in y_train]\n",
        "    y_valid_new = [[tag[0] for tag in tag_seq] for tag_seq in y_valid]\n",
        "    y_test_new = [[tag[0] for tag in tag_seq] for tag_seq in y_test]\n",
        "\n",
        "    return y_train_new, y_valid_new, y_test_new "
      ],
      "metadata": {
        "id": "O2PS2tnCNvgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy_metrics(correct, total):\n",
        "    accuracy = sum(x for x in correct.values()) / sum(x for x in total.values())\n",
        "    \n",
        "    classwise_accuracy = {}\n",
        "\n",
        "\n",
        "    for tag in sorted(total.keys()):\n",
        "        classwise_accuracy[tag] = correct[tag] / total[tag]\n",
        "    \n",
        "    print(f'\\nHMM Model Accuracy = {accuracy}\\n')\n",
        "    print('Class-wise Accuracies \\n')\n",
        "    print(tabulate(zip(classwise_accuracy.keys(), classwise_accuracy.values()),\n",
        "                   headers=['Class (Tag)', 'Accuracy'],\n",
        "                   tablefmt='orgtbl'))\n",
        "    \n",
        "    df = pd.DataFrame.from_dict(classwise_accuracy, orient='index')\n",
        "    \n",
        "    return df, accuracy"
      ],
      "metadata": {
        "id": "gAV5CftYNgzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kappa(position, all_tags):\n",
        "    return all_tags if position not in [0, -1] else ['START']"
      ],
      "metadata": {
        "id": "CBGW7yUDPIzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram_viterbi_model(sentence, transition, emission, all_tags):\n",
        "    sentence = sentence.split()\n",
        "    pi = defaultdict(lambda: 0)\n",
        "    bp = defaultdict(lambda: \"OTH\")\n",
        "    pi[(0, 'START', 'START')] = 1.0\n",
        "\n",
        "    n = len(sentence)\n",
        "\n",
        "    for k in range(1, n + 1):\n",
        "        u_set = kappa(k - 1, all_tags)\n",
        "        v_set = kappa(k, all_tags)\n",
        "        w_set = kappa(k - 2, all_tags)\n",
        "\n",
        "        for v in v_set:\n",
        "            for u in u_set:\n",
        "                for w in w_set:\n",
        "                    reach_prob = pi[(k - 1, w, u)] * transition[(w, u, v)] * emission[(sentence[k - 1], v)]\n",
        "                    if reach_prob > pi[(k, u, v)]:\n",
        "                        pi[(k, u, v)] = reach_prob\n",
        "                        bp[(k, u, v)] = w\n",
        "    \n",
        "    u_set = kappa(n - 1, all_tags)\n",
        "    v_set = kappa(n, all_tags)\n",
        "    result_tags = []\n",
        "    for u in u_set:\n",
        "        for v in v_set:\n",
        "            if len(result_tags) == 0:\n",
        "                result_tags = [v, u]\n",
        "            if pi[(n, u, v)] * transition[(u, v, 'STOP')] > \\\n",
        "            pi[(n, result_tags[1], result_tags[0])] * transition[result_tags[1], result_tags[0], 'STOP']:\n",
        "                result_tags = [v, u]\n",
        "    \n",
        "    for k in range(n - 2, 0, -1):\n",
        "        result_tags.append(bp[(k + 2, result_tags[-1], result_tags[-2])])\n",
        "    \n",
        "    result_tags.reverse()\n",
        "\n",
        "    return result_tags"
      ],
      "metadata": {
        "id": "Af-Ax5xlPMEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_viterbi_model(sentence, transition, emission, all_tags):\n",
        "    sentence = sentence.split()\n",
        "    pi = defaultdict(lambda: 0)\n",
        "    bp = defaultdict(lambda: \"OTH\")\n",
        "    pi[(0, 'START')] = 1.0\n",
        "\n",
        "    n = len(sentence)\n",
        "\n",
        "    for k in range(1, n + 1):\n",
        "        u_set = kappa(k - 1, all_tags)\n",
        "        v_set = kappa(k, all_tags)\n",
        "\n",
        "        for v in v_set:\n",
        "            for u in u_set:\n",
        "                reach_prob = pi[(k - 1, u)] * transition[(u, v)] * emission[(sentence[k - 1], v)]\n",
        "                if reach_prob > pi[(k, v)]:\n",
        "                    pi[(k, v)] = reach_prob\n",
        "                    bp[(k, v)] = u\n",
        "    \n",
        "    #u_set = kappa(n - 1, all_tags)\n",
        "    \n",
        "    v_set = kappa(n, all_tags)\n",
        "    result_tags = []\n",
        "    for v in v_set:\n",
        "        if len(result_tags) == 0:\n",
        "            result_tags = [v]\n",
        "        if pi[(n, v)] * transition[(v, 'STOP')] > \\\n",
        "        pi[(n, result_tags[0])] * transition[result_tags[0], 'STOP']:\n",
        "                result_tags = [v]\n",
        "    \n",
        "    for k in range(n - 1, 0, -1):\n",
        "        result_tags.append(bp[(k + 1, result_tags[-1])])\n",
        "    \n",
        "    result_tags.reverse()\n",
        "\n",
        "    return result_tags"
      ],
      "metadata": {
        "id": "0uDz5XPxBBhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tricontext_viterbi_model(sentence, transition, emission, all_tags):\n",
        "    sentence = sentence.split()\n",
        "    pi = defaultdict(lambda: 0)\n",
        "    bp = defaultdict(lambda: \"OTH\")\n",
        "    pi[(0, 'START', 'START')] = 1.0\n",
        "\n",
        "    n = len(sentence)\n",
        "\n",
        "    for k in range(1, n + 1):\n",
        "        u_set = kappa(k - 1, all_tags)\n",
        "        v_set = kappa(k, all_tags)\n",
        "        w_set = kappa(k - 2, all_tags)\n",
        "\n",
        "        for v in v_set:\n",
        "            for u in u_set:\n",
        "                for w in w_set:\n",
        "                    reach_prob = pi[(k - 1, w, u)] * transition[(w, u, v)] * emission[(sentence[k - 1], u, v)]\n",
        "                    if reach_prob > pi[(k, u, v)]:\n",
        "                        pi[(k, u, v)] = reach_prob\n",
        "                        bp[(k, u, v)] = w\n",
        "    \n",
        "    u_set = kappa(n - 1, all_tags)\n",
        "    v_set = kappa(n, all_tags)\n",
        "    result_tags = []\n",
        "    for u in u_set:\n",
        "        for v in v_set:\n",
        "            if len(result_tags) == 0:\n",
        "                result_tags = [v, u]\n",
        "            if pi[(n, u, v)] * transition[(u, v, 'STOP')] > \\\n",
        "            pi[(n, result_tags[1], result_tags[0])] * transition[result_tags[1], result_tags[0], 'STOP']:\n",
        "                result_tags = [v, u]\n",
        "    \n",
        "    for k in range(n - 2, 0, -1):\n",
        "        result_tags.append(bp[(k + 2, result_tags[-1], result_tags[-2])])\n",
        "    \n",
        "    result_tags.reverse()\n",
        "\n",
        "    return result_tags"
      ],
      "metadata": {
        "id": "D76JYTMD0FnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bicontext_viterbi_model(sentence, transition, emission, all_tags):\n",
        "    sentence = sentence.split()\n",
        "    pi = defaultdict(lambda: 0)\n",
        "    bp = defaultdict(lambda: \"OTH\")\n",
        "    pi[(0, 'START')] = 1.0\n",
        "\n",
        "    n = len(sentence)\n",
        "\n",
        "    for k in range(1, n + 1):\n",
        "        u_set = kappa(k - 1, all_tags)\n",
        "        v_set = kappa(k, all_tags)\n",
        "\n",
        "        for v in v_set:\n",
        "            for u in u_set:\n",
        "                reach_prob = pi[(k - 1, u)] * transition[(u, v)] * emission[(sentence[k - 1], u, v)]\n",
        "                if reach_prob > pi[(k, v)]:\n",
        "                    pi[(k, v)] = reach_prob\n",
        "                    bp[(k, v)] = u\n",
        "    \n",
        "    #u_set = kappa(n - 1, all_tags)\n",
        "    \n",
        "    v_set = kappa(n, all_tags)\n",
        "    result_tags = []\n",
        "    for v in v_set:\n",
        "        if len(result_tags) == 0:\n",
        "            result_tags = [v]\n",
        "        if pi[(n, v)] * transition[(v, 'STOP')] > \\\n",
        "        pi[(n, result_tags[0])] * transition[result_tags[0], 'STOP']:\n",
        "                result_tags = [v]\n",
        "    \n",
        "    for k in range(n - 1, 0, -1):\n",
        "        result_tags.append(bp[(k + 1, result_tags[-1])])\n",
        "    \n",
        "    result_tags.reverse()\n",
        "\n",
        "    return result_tags"
      ],
      "metadata": {
        "id": "tBHgvLj-0SKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_and_evaluate(x, y, transition, emission, all_tags, order = \"tri\", context = \"no\"):\n",
        "    correct_predictions = defaultdict(lambda: 0)\n",
        "    tag_count = defaultdict(lambda: 0)\n",
        "\n",
        "    print(f'Evaluating {len(x)} sentences.\\n')\n",
        "\n",
        "    labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for sentence, actual_tag_sequence in tqdm(zip(x, y), total=len(x)):\n",
        "        if (order == \"tri\" and context == \"no\") :\n",
        "            pred_tag_sequence = trigram_viterbi_model(sentence, transition, emission, all_tags)\n",
        "        elif (order == \"bi\" and context == \"no\") :\n",
        "            pred_tag_sequence = bigram_viterbi_model(sentence, transition, emission, all_tags)\n",
        "        elif (order == \"tri\" and context == \"yes\") :\n",
        "            pred_tag_sequence = tricontext_viterbi_model(sentence, transition, emission, all_tags)\n",
        "        else :\n",
        "            pred_tag_sequence = bicontext_viterbi_model(sentence, transition, emission, all_tags)\n",
        "        \n",
        "        labels.extend(actual_tag_sequence)\n",
        "        predictions.extend(pred_tag_sequence)\n",
        "        \n",
        "        for predicted, actual in zip(pred_tag_sequence, actual_tag_sequence):\n",
        "            correct_predictions[actual] += predicted == actual\n",
        "            tag_count[actual] += 1\n",
        "    \n",
        "    df, accuracy = evaluate_accuracy_metrics(correct_predictions, tag_count)   \n",
        "\n",
        "    return df, accuracy, labels, predictions"
      ],
      "metadata": {
        "id": "xkKWujl4NkmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HMM(x_train, y_train, x_valid, y_valid, x_test, y_test, tag_set):\n",
        "\n",
        "    if(len(tag_set) == 3):\n",
        "        y_train, y_valid, y_test = collapse_to_3_tags(y_train, y_valid, y_test)\n",
        "\n",
        "    all_tags = ['START'] + list(tag_set) + ['STOP']\n",
        "\n",
        "    emission_matrix, emission_context = generate_emission_matrix(x_train, y_train)\n",
        "    tri_transition_matrix, bi_transition_matrix = generate_transition_matrix(y_train)\n",
        "\n",
        "\n",
        "    print(\"\\n\\nTrigram Model with No Context Validation Results\")\n",
        "    _, acc1, _, _ = test_and_evaluate(x_valid, y_valid, tri_transition_matrix, emission_matrix, all_tags, order = \"tri\", context = \"no\")\n",
        "\n",
        "    print(\"\\n\\nBigram Model with No Context Validation Results\")\n",
        "    _, acc2, _, _ = test_and_evaluate(x_valid, y_valid, bi_transition_matrix, emission_matrix, all_tags, order = \"bi\", context = \"no\")\n",
        "\n",
        "    print(\"\\n\\nTrigram Model with Context Validation Results\")\n",
        "    _, acc3, _, _ = test_and_evaluate(x_valid, y_valid, tri_transition_matrix, emission_context, all_tags, order = \"tri\", context = \"yes\")\n",
        "\n",
        "    print(\"\\n\\nBigram Model with Context Validation Results\")\n",
        "    _, acc4, _, _ = test_and_evaluate(x_valid, y_valid, bi_transition_matrix, emission_context, all_tags, order = \"bi\", context = \"yes\")\n",
        "    \n",
        "    accuracy = max(acc1, acc2, acc3, acc4)\n",
        "\n",
        "    print(\"\\n\\nBest Model Test Dataset Results\\n\")\n",
        "    if(accuracy == acc1):\n",
        "      df, acc, labels, predict = test_and_evaluate(x_test, y_test, tri_transition_matrix, emission_matrix, all_tags, order = \"tri\", context = \"no\")\n",
        "    elif(accuracy == acc2):\n",
        "      df, acc, labels, predict = test_and_evaluate(x_test, y_test, bi_transition_matrix, emission_matrix, all_tags, order = \"bi\", context = \"no\")\n",
        "    elif(accuracy == acc3):\n",
        "      df, acc, labels, predict = test_and_evaluate(x_test, y_test, tri_transition_matrix, emission_context, all_tags, order = \"tri\", context = \"yes\")\n",
        "    else:\n",
        "      df, acc, labels, predict = test_and_evaluate(x_test, y_test, bi_transition_matrix, emission_context, all_tags, order = \"bi\", context = \"yes\")\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "Zc7EzGTaI-6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    x_train, y_train, tag_set = load_dataset(\"train.txt\")\n",
        "    x_valid, y_valid, _ = load_dataset(\"dev.txt\")\n",
        "    x_test, y_test, _ = load_dataset(\"test.txt\")\n",
        "    \n",
        "    # For all the tags\n",
        "    print('-' * 80)\n",
        "    print('HMM for 3 tags : ')\n",
        "    tag_set = set(['B', 'I', 'O'])\n",
        "    df = HMM(x_train, y_train, x_valid, y_valid, x_test, y_test, tag_set)\n",
        "    df.to_csv(\"HMM_3_results.csv\")\n",
        "    print('-' * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64YmXXR7Sw_8",
        "outputId": "30a194b3-c3fe-4b62-d7d8-a6e567206c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "HMM for 3 tags : \n",
            "\n",
            "\n",
            "Trigram Model with No Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:01<00:00, 520.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9037574564909907\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B             |   0.20121  |\n",
            "| I             |   0.117773 |\n",
            "| O             |   0.9587   |\n",
            "\n",
            "\n",
            "Bigram Model with No Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 2452.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9015435705061189\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B             |   0.2118   |\n",
            "| I             |   0.100642 |\n",
            "| O             |   0.956387 |\n",
            "\n",
            "\n",
            "Trigram Model with Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 454.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.912121025767173\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B             |   0.192133 |\n",
            "| I             |   0.130621 |\n",
            "| O             |   0.967687 |\n",
            "\n",
            "\n",
            "Bigram Model with Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1992.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9114445606051288\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B             |   0.193646 |\n",
            "| I             |   0.122056 |\n",
            "| O             |   0.967158 |\n",
            "\n",
            "\n",
            "Best Model Test Dataset Results\n",
            "\n",
            "Evaluating 3849 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3849/3849 [00:08<00:00, 466.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.8859377019516609\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B             |   0.183703 |\n",
            "| I             |   0.130137 |\n",
            "| O             |   0.963068 |\n",
            "61896 60033\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"HMM_3_results.csv\")\n",
        "df.columns = ['POS', 'Probability']\n",
        "df.to_csv(\"HMM_4_results.csv\", index = None)\n",
        "df"
      ],
      "metadata": {
        "id": "ZqxC5UywxE2O",
        "outputId": "bda6ede2-e329-4032-f1c3-2fd991873b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd66caac-6e18-4bd8-9991-e7c9315aeb28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POS</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>0.183703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>0.130137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O</td>\n",
              "      <td>0.963068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd66caac-6e18-4bd8-9991-e7c9315aeb28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd66caac-6e18-4bd8-9991-e7c9315aeb28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd66caac-6e18-4bd8-9991-e7c9315aeb28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  POS  Probability\n",
              "0   B     0.183703\n",
              "1   I     0.130137\n",
              "2   O     0.963068"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    x_train, y_train, tag_set = load_dataset(\"train.txt\")\n",
        "    x_valid, y_valid, _ = load_dataset(\"dev.txt\")\n",
        "    x_test, y_test, _ = load_dataset(\"test.txt\")\n",
        "\n",
        "    # For all the tags\n",
        "    print('-' * 80)\n",
        "    print('HMM for 21 tags : ')\n",
        "    df = HMM(x_train, y_train, x_valid, y_valid, x_test, y_test, tag_set)\n",
        "    df.to_csv(\"HMM_21_results.csv\")\n",
        "\n",
        "    print('-' * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcspZBv0zmfR",
        "outputId": "62847350-a409-4536-dd2f-96667c2782f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "HMM for 21 tags : \n",
            "\n",
            "\n",
            "Trigram Model with No Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:39<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9002521370149438\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B-company     |  0.153846  |\n",
            "| B-facility    |  0.0526316 |\n",
            "| B-loc         |  0.284483  |\n",
            "| B-movie       |  0         |\n",
            "| B-musicartist |  0.0243902 |\n",
            "| B-other       |  0.106061  |\n",
            "| B-person      |  0.157895  |\n",
            "| B-product     |  0.189189  |\n",
            "| B-sportsteam  |  0.0285714 |\n",
            "| B-tvshow      |  0         |\n",
            "| I-company     |  0         |\n",
            "| I-facility    |  0.102564  |\n",
            "| I-loc         |  0.166667  |\n",
            "| I-movie       |  0         |\n",
            "| I-musicartist |  0.0285714 |\n",
            "| I-other       |  0.0412371 |\n",
            "| I-person      |  0.0842105 |\n",
            "| I-product     |  0.0165289 |\n",
            "| I-sportsteam  |  0.0769231 |\n",
            "| O             |  0.959492  |\n",
            "\n",
            "\n",
            "Bigram Model with No Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:06<00:00, 154.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.8979152573642457\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B-company     | 0.153846   |\n",
            "| B-facility    | 0.0526316  |\n",
            "| B-loc         | 0.284483   |\n",
            "| B-movie       | 0          |\n",
            "| B-musicartist | 0.0243902  |\n",
            "| B-other       | 0.106061   |\n",
            "| B-person      | 0.175439   |\n",
            "| B-product     | 0.189189   |\n",
            "| B-sportsteam  | 0.0285714  |\n",
            "| B-tvshow      | 0          |\n",
            "| I-company     | 0          |\n",
            "| I-facility    | 0.102564   |\n",
            "| I-loc         | 0.166667   |\n",
            "| I-movie       | 0          |\n",
            "| I-musicartist | 0.0285714  |\n",
            "| I-other       | 0.0412371  |\n",
            "| I-person      | 0.0631579  |\n",
            "| I-product     | 0.00826446 |\n",
            "| I-sportsteam  | 0.0769231  |\n",
            "| O             | 0.956981   |\n",
            "\n",
            "\n",
            "Trigram Model with Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:50<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9095381587848226\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B-company     | 0.153846   |\n",
            "| B-facility    | 0.0526316  |\n",
            "| B-loc         | 0.25       |\n",
            "| B-movie       | 0          |\n",
            "| B-musicartist | 0.0243902  |\n",
            "| B-other       | 0.0833333  |\n",
            "| B-person      | 0.128655   |\n",
            "| B-product     | 0.108108   |\n",
            "| B-sportsteam  | 0          |\n",
            "| B-tvshow      | 0          |\n",
            "| I-company     | 0          |\n",
            "| I-facility    | 0.0769231  |\n",
            "| I-loc         | 0.166667   |\n",
            "| I-movie       | 0          |\n",
            "| I-musicartist | 0          |\n",
            "| I-other       | 0.0412371  |\n",
            "| I-person      | 0.136842   |\n",
            "| I-product     | 0.00826446 |\n",
            "| I-sportsteam  | 0          |\n",
            "| O             | 0.970528   |\n",
            "\n",
            "\n",
            "Bigram Model with Context Validation Results\n",
            "Evaluating 1000 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:09<00:00, 107.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.9094151651189963\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B-company     |  0.153846  |\n",
            "| B-facility    |  0.0263158 |\n",
            "| B-loc         |  0.25      |\n",
            "| B-movie       |  0         |\n",
            "| B-musicartist |  0.0243902 |\n",
            "| B-other       |  0.0833333 |\n",
            "| B-person      |  0.140351  |\n",
            "| B-product     |  0.108108  |\n",
            "| B-sportsteam  |  0         |\n",
            "| B-tvshow      |  0         |\n",
            "| I-company     |  0         |\n",
            "| I-facility    |  0.0512821 |\n",
            "| I-loc         |  0.190476  |\n",
            "| I-movie       |  0         |\n",
            "| I-musicartist |  0         |\n",
            "| I-other       |  0.0515464 |\n",
            "| I-person      |  0.147368  |\n",
            "| I-product     |  0         |\n",
            "| I-sportsteam  |  0         |\n",
            "| O             |  0.970264  |\n",
            "\n",
            "\n",
            "Best Model Test Dataset Results\n",
            "\n",
            "Evaluating 3849 sentences.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3849/3849 [11:26<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Model Accuracy = 0.8806061781052087\n",
            "\n",
            "Class-wise Accuracies \n",
            "\n",
            "| Class (Tag)   |   Accuracy |\n",
            "|---------------+------------|\n",
            "| B-company     |  0.0772947 |\n",
            "| B-facility    |  0.0632411 |\n",
            "| B-loc         |  0.226757  |\n",
            "| B-movie       |  0         |\n",
            "| B-musicartist |  0.0052356 |\n",
            "| B-other       |  0.0273973 |\n",
            "| B-person      |  0.136929  |\n",
            "| B-product     |  0.0203252 |\n",
            "| B-sportsteam  |  0.0204082 |\n",
            "| B-tvshow      |  0         |\n",
            "| I-company     |  0.045283  |\n",
            "| I-facility    |  0.103825  |\n",
            "| I-loc         |  0.0913242 |\n",
            "| I-movie       |  0         |\n",
            "| I-musicartist |  0.0142857 |\n",
            "| I-other       |  0.0647482 |\n",
            "| I-person      |  0.103333  |\n",
            "| I-product     |  0.002     |\n",
            "| I-sportsteam  |  0         |\n",
            "| I-tvshow      |  0         |\n",
            "| O             |  0.965499  |\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"HMM_21_results.csv\")\n",
        "df.columns = ['POS', 'Probability']\n",
        "df.to_csv(\"HMM_21_results.csv\", index = None)\n",
        "df"
      ],
      "metadata": {
        "id": "HSWlixu_wWfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}